#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import feedparser
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
import os
import time
import hashlib
import requests
import re
from datetime import datetime, timedelta
import sys

# í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ì½ê¸°
def get_config():
    """í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ì •ë³´ ì½ê¸°"""
    try:
        # Google Sheets ì¸ì¦ ì •ë³´
        google_creds = os.environ.get('GOOGLE_CREDENTIALS')
        if not google_creds:
            raise ValueError("GOOGLE_CREDENTIALS í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # JSON íŒŒì‹± (í™˜ê²½ë³€ìˆ˜ëŠ” ì´ë¯¸ JSON ë¬¸ìì—´)
        try:
            creds_dict = json.loads(google_creds)
            print("âœ… Google Credentials JSON íŒŒì‹± ì„±ê³µ")
        except json.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"ğŸ“ ë°›ì€ ë°ì´í„° ê¸¸ì´: {len(google_creds)} ë¬¸ì")
            print(f"ğŸ“ ë°ì´í„° ì‹œì‘ ë¶€ë¶„: {google_creds[:100]}...")
            raise ValueError(f"GOOGLE_CREDENTIALS JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        # Google Sheets ID
        sheets_id = os.environ.get('GOOGLE_SHEETS_ID')
        if not sheets_id:
            raise ValueError("GOOGLE_SHEETS_ID í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        print(f"âœ… Google Sheets ID: {sheets_id[:20]}...")
        return creds_dict, sheets_id
        
    except Exception as e:
        print(f"âŒ ì„¤ì • ì½ê¸° ì‹¤íŒ¨: {e}")
        sys.exit(1)

# RSS í”¼ë“œ ëª©ë¡ - ë„¤ì´ë²„ì™€ êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ (í‚¤ì›Œë“œë³„)
RSS_FEEDS = [
    # ë„¤ì´ë²„ ë‰´ìŠ¤ RSS
    "http://newssearch.naver.com/search.naver?where=rss&query=íŒŒì´í”„íŠ¸ë¦¬",
    "http://newssearch.naver.com/search.naver?where=rss&query=íŒŒë¨¸ìŠ¤ë§ˆì¸ë“œ", 
    "http://newssearch.naver.com/search.naver?where=rss&query=paiptree",
    "http://newssearch.naver.com/search.naver?where=rss&query=farmersmind",
    # êµ¬ê¸€ ë‰´ìŠ¤ RSS
    "https://news.google.com/rss/search?q=íŒŒì´í”„íŠ¸ë¦¬&hl=ko&gl=KR&ceid=KR:ko",
    "https://news.google.com/rss/search?q=íŒŒë¨¸ìŠ¤ë§ˆì¸ë“œ&hl=ko&gl=KR&ceid=KR:ko",
    "https://news.google.com/rss/search?q=paiptree&hl=ko&gl=KR&ceid=KR:ko",
    "https://news.google.com/rss/search?q=farmersmind&hl=ko&gl=KR&ceid=KR:ko"
]

# ê²€ìƒ‰ í‚¤ì›Œë“œ (ì´ë¯¸ RSSì—ì„œ í•„í„°ë§ë˜ë¯€ë¡œ ì „ì²´ ë§¤ì¹­)
KEYWORDS = [
    "íŒŒì´í”„íŠ¸ë¦¬", "íŒŒë¨¸ìŠ¤ë§ˆì¸ë“œ", "paiptree", "farmersmind"
]

def clean_news_description(description, source_name):
    """
    ë‰´ìŠ¤ descriptionì—ì„œ ì–¸ë¡ ì‚¬ëª…ê³¼ ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±°
    """
    if not description:
        return ""
    
    # HTML íƒœê·¸ ì œê±°
    description = re.sub(r'<[^>]+>', '', description)
    
    # HTML ì—”í‹°í‹° ë””ì½”ë”©
    import html
    description = html.unescape(description)
    
    # ì–¸ë¡ ì‚¬ëª… ì œê±° íŒ¨í„´ë“¤
    source_clean = re.escape(source_name) if source_name else ''
    
    # íŒ¨í„´ 1: "ë‚´ìš© - ì–¸ë¡ ì‚¬ëª…" (ëë¶€ë¶„)
    description = re.sub(rf'\s*-\s*{source_clean}\s*$', '', description, flags=re.IGNORECASE)
    
    # íŒ¨í„´ 2: "ë‚´ìš© (ì–¸ë¡ ì‚¬ëª…)" (ëë¶€ë¶„)
    description = re.sub(rf'\s*\({source_clean}\)\s*$', '', description, flags=re.IGNORECASE)
    
    # íŒ¨í„´ 3: "ë‚´ìš©... ì–¸ë¡ ì‚¬ëª…" (ëë¶€ë¶„)
    description = re.sub(rf'\s*{source_clean}\s*$', '', description, flags=re.IGNORECASE)
    
    # ì¼ë°˜ì ì¸ ë‰´ìŠ¤ ì œê³µì—…ì²´ ì œê±° íŒ¨í„´
    news_providers = ['ì—°í•©ë‰´ìŠ¤', 'ë‰´ìŠ¤1', 'ë‰´ì‹œìŠ¤', 'YTN', 'SBS', 'MBC', 'KBS', 'ì¡°ì„ ì¼ë³´', 'ë™ì•„ì¼ë³´', 'ì¤‘ì•™ì¼ë³´', 'í•œê²¨ë ˆ', 'ê²½í–¥ì‹ ë¬¸']
    for provider in news_providers:
        provider_escaped = re.escape(provider)
        description = re.sub(rf'\s*-\s*{provider_escaped}\s*$', '', description, flags=re.IGNORECASE)
        description = re.sub(rf'\s*\({provider_escaped}\)\s*$', '', description, flags=re.IGNORECASE)
        description = re.sub(rf'\s*{provider_escaped}\s*$', '', description, flags=re.IGNORECASE)
    
    # ë¶ˆí•„ìš”í•œ ë¬¸êµ¬ ì œê±°
    unwanted_phrases = [
        r'\s*\[.*?\]\s*$',  # [ê¸°ìëª…] ë“±
        r'\s*=.*?=\s*$',   # =ì—°í•©ë‰´ìŠ¤= ë“±
        r'\s*\(.*?ê¸°ì\)\s*$',  # (í™ê¸¸ë™ ê¸°ì) ë“±
    ]
    
    for pattern in unwanted_phrases:
        description = re.sub(pattern, '', description, flags=re.IGNORECASE)
    
    # ë‹¤ì¤‘ ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜
    description = re.sub(r'\s+', ' ', description)
    
    # ì•ë’¤ ê³µë°± ì œê±°
    description = description.strip()
    
    return description

def setup_google_sheets(creds_dict, sheets_id):
    """Google Sheets ì—°ê²° ì„¤ì •"""
    try:
        print("ğŸ”— Google Sheets ì—°ê²° ì¤‘...")
        
        # ì¸ì¦ ë²”ìœ„ ì„¤ì •
        scope = [
            'https://spreadsheets.google.com/feeds',
            'https://www.googleapis.com/auth/drive'
        ]
        
        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        credentials = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
        gc = gspread.authorize(credentials)
        
        # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸°
        sheet = gc.open_by_key(sheets_id)
        
        # news_data ì›Œí¬ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
        try:
            worksheet = sheet.worksheet('news_data')
            print("âœ… ê¸°ì¡´ news_data ì‹œíŠ¸ ë°œê²¬")
        except gspread.WorksheetNotFound:
            print("ğŸ“ news_data ì‹œíŠ¸ ìƒì„± ì¤‘...")
            worksheet = sheet.add_worksheet(title='news_data', rows=1000, cols=21)
            
            # Materials í‘œì¤€ 21ê°œ ì»¬ëŸ¼ (A-U) í—¤ë” ì¶”ê°€
            headers = [
                'id', 'title', 'description', 'category', 'tags',                    # A-E
                'upload_date', 'file_size', 'file_format', 'dimensions',             # F-I
                'creator', 'brand_alignment', 'usage_rights', 'version',             # J-M
                'download_count', 'rating', 'thumbnail_url', 'file_url',            # N-Q
                'original_url', 'status', 'featured', 'created_at'                  # R-U
            ]
            worksheet.append_row(headers)
            print("âœ… news_data ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
        
        return worksheet
    except Exception as e:
        print(f"âŒ Google Sheets ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit(1)

def fetch_rss_news(rss_url, keywords, initial_mode=False):
    """RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    news_items = []
    
    try:
        print(f"ğŸ“¡ RSS í”¼ë“œ í™•ì¸ ì¤‘: {rss_url}")
        
        # RSS í”¼ë“œ íŒŒì‹±
        feed = feedparser.parse(rss_url)
        
        if feed.bozo:
            print(f"âš ï¸ RSS í”¼ë“œ íŒŒì‹± ê²½ê³ : {rss_url}")
        
        total_entries = len(feed.entries) if hasattr(feed, 'entries') else 0
        print(f"ğŸ“Š ì´ {total_entries}ê°œ RSS ì—”íŠ¸ë¦¬ ë°œê²¬")
        
        # ì´ˆê¸° ëª¨ë“œì¼ ë•ŒëŠ” ëª¨ë“  ë‰´ìŠ¤ ìˆ˜ì§‘, ì¼ë°˜ ëª¨ë“œì¼ ë•ŒëŠ” ìµœê·¼ ë‰´ìŠ¤ë§Œ
        entries_to_process = feed.entries if hasattr(feed, 'entries') else []
        
        if not initial_mode:
            # ì¼ë°˜ ëª¨ë“œ: ìµœê·¼ 7ì¼ ì´ë‚´ ë‰´ìŠ¤ë§Œ
            seven_days_ago = datetime.now() - timedelta(days=7)
            recent_entries = []
            for entry in entries_to_process:
                published = entry.get('published_parsed')
                if published:
                    pub_date = datetime(*published[:6])
                    if pub_date >= seven_days_ago:
                        recent_entries.append(entry)
                else:
                    # ë‚ ì§œ ì •ë³´ê°€ ì—†ìœ¼ë©´ ìµœê·¼ìœ¼ë¡œ ê°„ì£¼
                    recent_entries.append(entry)
            entries_to_process = recent_entries
            print(f"ğŸ—“ï¸ ìµœê·¼ 7ì¼ ì´ë‚´ ë‰´ìŠ¤: {len(entries_to_process)}ê°œ")
        else:
            print(f"ğŸ¯ ì´ˆê¸° ìˆ˜ì§‘ ëª¨ë“œ: ëª¨ë“  ê°€ëŠ¥í•œ ë‰´ìŠ¤ ({len(entries_to_process)}ê°œ) ì²˜ë¦¬")
        
        # ê° ë‰´ìŠ¤ ì•„ì´í…œ í™•ì¸
        for entry in entries_to_process:
            title = entry.get('title', '')
            description = entry.get('description', '') or entry.get('summary', '')
            link = entry.get('link', '')
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
            content_to_check = f"{title} {description}".lower()
            matched_keywords = [kw for kw in keywords if kw.lower() in content_to_check]
            
            if matched_keywords:
                # ë°œí–‰ì¼ì ì²˜ë¦¬
                published = entry.get('published_parsed')
                if published:
                    pub_date = datetime(*published[:6]).strftime('%Y-%m-%d')
                    pub_datetime = datetime(*published[:6])
                else:
                    pub_date = datetime.now().strftime('%Y-%m-%d')
                    pub_datetime = datetime.now()
                
                # ì–¸ë¡ ì‚¬ëª… ì¶”ì¶œ
                source = feed.feed.get('title', 'Unknown')
                
                # ğŸš€ Description ì •ë¦¬ ì ìš©
                cleaned_description = clean_news_description(description, source)
                
                # ğŸš€ ì´ë¯¸ì§€ ì—†ì´ ë‹¨ìˆœí•œ ë‰´ìŠ¤ ìˆ˜ì§‘ìœ¼ë¡œ ë³€ê²½
                thumbnail_url = ""  # ì´ë¯¸ì§€ ê¸°ëŠ¥ ì œê±°
                
                news_item = {
                    'title': title[:200],  # ì œëª© ê¸¸ì´ ì œí•œ
                    'description': cleaned_description[:500],  # ì •ë¦¬ëœ ì„¤ëª… ì‚¬ìš©
                    'category': source,
                    'tags': ','.join(matched_keywords),
                    'upload_date': pub_date,
                    'pub_datetime': pub_datetime,  # ì •ë ¬ìš©
                    'download_count': 0,  # ê¸°ë³¸ê°’ 0
                    'thumbnail_url': thumbnail_url,
                    'original_url': link
                }
                
                news_items.append(news_item)
                print(f"âœ… í‚¤ì›Œë“œ ë§¤ì¹­: {title[:50]}... (í‚¤ì›Œë“œ: {matched_keywords}) [{pub_date}]")
                print(f"ğŸ§¹ ì •ë¦¬ëœ ì„¤ëª…: {cleaned_description[:100]}...")
        
        print(f"ğŸ“Š {rss_url}ì—ì„œ {len(news_items)}ê°œ ë§¤ì¹­ ë‰´ìŠ¤ ë°œê²¬")
        return news_items
        
    except Exception as e:
        print(f"âŒ RSS í”¼ë“œ ì²˜ë¦¬ ì‹¤íŒ¨ {rss_url}: {e}")
        return []

def generate_sequential_id(worksheet):
    """ê¸°ì¡´ ë°ì´í„° í™•ì¸í•´ì„œ ë‹¤ìŒ ë²ˆí˜¸ ìƒì„± (001, 002, 003...)"""
    try:
        all_records = worksheet.get_all_records()
        if not all_records:
            return "001"
        
        # ê¸°ì¡´ IDì—ì„œ ìˆ«ì ì¶”ì¶œí•´ì„œ ìµœëŒ€ê°’ ì°¾ê¸°
        max_num = 0
        for record in all_records:
            try:
                current_id = str(record.get('id', '0'))
                # ìˆ«ìë§Œ ì¶”ì¶œ (ì•ì˜ 0 ì œê±°)
                num = int(current_id.lstrip('0')) if current_id.strip() else 0
                max_num = max(max_num, num)
            except (ValueError, TypeError):
                continue
        
        # ë‹¤ìŒ ë²ˆí˜¸ë¥¼ 3ìë¦¬ë¡œ í¬ë§·íŒ…
        next_num = max_num + 1
        return f"{next_num:03d}"
        
    except Exception as e:
        print(f"âš ï¸ ID ìƒì„± ì‹¤íŒ¨, ì„ì‹œ ID ì‚¬ìš©: {e}")
        # ì‹¤íŒ¨ì‹œ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ID
        return f"{int(time.time() % 10000):04d}"

def is_duplicate_news(worksheet, original_url):
    """ì¤‘ë³µ ë‰´ìŠ¤ í™•ì¸ (URL ê¸°ë°˜)"""
    try:
        # ëª¨ë“  ê¸°ì¡´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        all_records = worksheet.get_all_records()
        
        for record in all_records:
            # URLì´ ì¼ì¹˜í•˜ë©´ ì¤‘ë³µ
            if record.get('original_url') == original_url:
                return True
        
        return False
    except Exception as e:
        print(f"âš ï¸ ì¤‘ë³µ í™•ì¸ ì‹¤íŒ¨: {e}")
        return False

def add_news_to_sheet(worksheet, news_item):
    """Google Sheetsì— ë‰´ìŠ¤ ì¶”ê°€"""
    try:
        # ì¤‘ë³µ í™•ì¸ (URL ê¸°ë°˜)
        if is_duplicate_news(worksheet, news_item['original_url']):
            print(f"â­ï¸ ì¤‘ë³µ ë‰´ìŠ¤ ìŠ¤í‚µ: {news_item['title'][:50]}...")
            return False
        
        # ìˆœì°¨ ID ìƒì„±
        news_id = generate_sequential_id(worksheet)
        
        # Materials í‘œì¤€ 21ê°œ ì»¬ëŸ¼ì— ë§ì¶˜ ë°ì´í„° ìƒì„±
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        row_data = [
            news_id,                                    # A: id
            news_item['title'],                         # B: title
            news_item['description'],                   # C: description
            news_item['category'],                      # D: category (ì–¸ë¡ ì‚¬)
            news_item['tags'],                          # E: tags
            news_item['upload_date'],                   # F: upload_date
            'N/A',                                      # G: file_size (ë‰´ìŠ¤ëŠ” íŒŒì¼ ì•„ë‹˜)
            'news',                                     # H: file_format (ë‰´ìŠ¤ íƒ€ì…)
            'N/A',                                      # I: dimensions
            news_item['category'],                      # J: creator (ì–¸ë¡ ì‚¬ëª…)
            'high',                                     # K: brand_alignment (ë¸Œëœë“œ ì—°ê´€ë„ ë†’ìŒ)
            'read-only',                               # L: usage_rights (ì½ê¸°ì „ìš©)
            '1.0',                                      # M: version
            news_item['download_count'],                # N: download_count
            '0',                                        # O: rating (ê¸°ë³¸ 0ì )
            '',                                         # P: thumbnail_url (ì´ë¯¸ì§€ ì œê±°)
            news_item['original_url'],                  # Q: file_url (ì›ë¬¸ ë§í¬)
            news_item['original_url'],                  # R: original_url (ë™ì¼)
            'active',                                   # S: status (í™œì„± ìƒíƒœ)
            'false',                                    # T: featured (ê¸°ë³¸ ë¹„ì¶”ì²œ)
            current_time                                # U: created_at (ìƒì„±ì‹œê°„)
        ]
        
        worksheet.append_row(row_data)
        print(f"âœ… ë‰´ìŠ¤ ì¶”ê°€ (ID: {news_id}): {news_item['title'][:50]}...")
        return True
        
    except Exception as e:
        print(f"âŒ ë‰´ìŠ¤ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Paiptree ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘")
    print(f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ§¹ Description ì •ë¦¬ ê¸°ëŠ¥ í™œì„±í™”ë¨")
    
    # ì´ˆê¸° ìˆ˜ì§‘ ëª¨ë“œ í™•ì¸ (í™˜ê²½ë³€ìˆ˜)
    initial_mode = os.environ.get('INITIAL_COLLECTION', 'false').lower() == 'true'
    
    if initial_mode:
        print("ğŸ¯ ì´ˆê¸° ëŒ€ëŸ‰ ìˆ˜ì§‘ ëª¨ë“œ í™œì„±í™”")
        print("ğŸ“š ê°€ëŠ¥í•œ ëª¨ë“  ê³¼ê±° ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
    else:
        print("ğŸ“… ì¼ë°˜ ëª¨ë“œ: ìµœê·¼ 7ì¼ ì´ë‚´ ë‰´ìŠ¤ë§Œ ìˆ˜ì§‘")
    
    start_time = time.time()
    
    # ì„¤ì • ì½ê¸°
    creds_dict, sheets_id = get_config()
    
    # Google Sheets ì—°ê²°
    worksheet = setup_google_sheets(creds_dict, sheets_id)
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘
    total_collected = 0
    total_found = 0
    all_news_items = []
    
    print(f"ğŸ” {len(RSS_FEEDS)}ê°œ RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
    print(f"ğŸ·ï¸ ê²€ìƒ‰ í‚¤ì›Œë“œ: {', '.join(KEYWORDS)}")
    
    for rss_url in RSS_FEEDS:
        news_items = fetch_rss_news(rss_url, KEYWORDS, initial_mode)
        total_found += len(news_items)
        all_news_items.extend(news_items)
    
    # ë°œí–‰ì¼ì ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
    all_news_items.sort(key=lambda x: x.get('pub_datetime', datetime.now()))
    
    print(f"\nğŸ“Š ì´ {len(all_news_items)}ê°œ ë‰´ìŠ¤ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¶”ê°€ ì¤‘...")
    
    # ì‹œíŠ¸ì— ì¶”ê°€
    for news_item in all_news_items:
        if add_news_to_sheet(worksheet, news_item):
            total_collected += 1
        
        # API í˜¸ì¶œ ì œí•œ ê³ ë ¤í•˜ì—¬ ì ì‹œ ëŒ€ê¸°
        time.sleep(0.5)
    
    # ì‹¤í–‰ ê²°ê³¼
    end_time = time.time()
    execution_time = round(end_time - start_time, 2)
    
    print(f"\nğŸ‰ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"ğŸ¯ ìˆ˜ì§‘ ëª¨ë“œ: {'ì´ˆê¸° ëŒ€ëŸ‰ ìˆ˜ì§‘' if initial_mode else 'ì¼ë°˜ ìˆ˜ì§‘'}")
    print(f"ğŸ“Š ì´ ë°œê²¬: {total_found}ê°œ")
    print(f"âœ… ìƒˆë¡œ ì¶”ê°€: {total_collected}ê°œ")
    print(f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {execution_time}ì´ˆ")
    print(f"ğŸ§¹ ëª¨ë“  descriptionì´ ì–¸ë¡ ì‚¬ëª… ì œê±° ì²˜ë¦¬ë¨")
    
    if total_collected == 0:
        print("â„¹ï¸ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"ğŸŒŸ {total_collected}ê°œì˜ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()
