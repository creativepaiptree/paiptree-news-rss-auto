#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
from bs4 import BeautifulSoup
import time
import re
import json
from urllib.parse import urljoin, urlparse
import logging

class ArticleImageScraper:
    def __init__(self, timeout=10, max_retries=3):
        self.timeout = timeout
        self.max_retries = max_retries
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
    
    def extract_first_image(self, article_url):
        """ê¸°ì‚¬ì—ì„œ ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” ì´ë¯¸ì§€ ì¶”ì¶œ - ìŠ¤ë§ˆíŠ¸ ë¡œì§ ê°•í™”"""
        try:
            print(f"ğŸ” ì´ë¯¸ì§€ ì¶”ì¶œ ì‹œì‘: {article_url}")
            
            # ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
            response = self._fetch_with_retry(article_url)
            if not response:
                print(f"âŒ ì›¹í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨: {article_url}")
                return None
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ì´ë¯¸ì§€ í›„ë³´ë“¤ ì°¾ê¸°
            image_candidates = []
            
            # 1. og:image ë©”íƒ€ íƒœê·¸ (ê°€ì¥ ìš°ì„ )
            og_image = soup.find('meta', property='og:image')
            if og_image and og_image.get('content'):
                image_url = og_image['content']
                if self._is_valid_image_url(image_url) and not self._is_excluded_image(image_url):
                    image_candidates.append({
                        'url': image_url,
                        'priority': 1,
                        'type': 'og_image',
                        'score': 100
                    })
                    print(f"âœ… og:image ë°œê²¬: {image_url}")
            
            # 2. êµ¬ì¡°í™” ë°ì´í„° ì´ë¯¸ì§€ (JSON-LD)
            json_ld_images = self._extract_structured_data_images(soup)
            for img_url in json_ld_images:
                if self._is_valid_image_url(img_url) and not self._is_excluded_image(img_url):
                    image_candidates.append({
                        'url': img_url,
                        'priority': 2,
                        'type': 'structured_data',
                        'score': 90
                    })
                    print(f"âœ… êµ¬ì¡°í™” ë°ì´í„° ì´ë¯¸ì§€ ë°œê²¬: {img_url}")
            
            # 3. ê¸°ì‚¬ ë³¸ë¬¸ ì˜ì—­ ë‚´ ì´ë¯¸ì§€ (CSS ì„ íƒì ìš°ì„ ìˆœìœ„)
            article_selectors = [
                'article img',
                'main img', 
                '.article-content img',
                '.content img',
                '.post-content img',
                '.entry-content img',
                '[data-article] img',
                '.article-body img'
            ]
            
            for selector in article_selectors:
                article_images = soup.select(selector)
                for img in article_images[:5]:  # ê° ì„ íƒìë‹¹ ìƒìœ„ 5ê°œë§Œ
                    src = img.get('src') or img.get('data-src')
                    if src and self._is_valid_image_url(src) and not self._is_excluded_image(src):
                        # ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                        score = self._calculate_image_score(img, selector)
                        if score >= 50:  # ìµœì†Œ ì ìˆ˜ ì´ìƒë§Œ ì„ íƒ
                            full_url = urljoin(article_url, src)
                            image_candidates.append({
                                'url': full_url,
                                'priority': 3,
                                'type': f'article_{selector.split()[0]}',
                                'score': score,
                                'width': img.get('width'),
                                'height': img.get('height'),
                                'alt': img.get('alt', '')
                            })
                            print(f"âœ… {selector} ì´ë¯¸ì§€ ë°œê²¬: {full_url} (ì ìˆ˜: {score})")
                break  # ì²« ë²ˆì§¸ ì„±ê³µí•œ ì„ íƒìì—ì„œë§Œ ê°€ì ¸ì˜¤ê¸°
            
            # 4. ì¼ë°˜ ì´ë¯¸ì§€ ì¤‘ í° ê²ƒë“¤ (ë” ì—„ê²©í•œ ê¸°ì¤€)
            if len(image_candidates) < 3:  # í›„ë³´ê°€ ë¶€ì¡±í•  ë•Œë§Œ
                general_images = soup.find_all('img', src=True)
                for img in general_images:
                    src = img.get('src')
                    if src and self._is_valid_image_url(src) and not self._is_excluded_image(src):
                        score = self._calculate_image_score(img, 'general')
                        if score >= 30:  # ì¼ë°˜ ì´ë¯¸ì§€ëŠ” ë” ë‚®ì€ ê¸°ì¤€
                            full_url = urljoin(article_url, src)
                            image_candidates.append({
                                'url': full_url,
                                'priority': 4,
                                'type': 'general',
                                'score': score
                            })
                            print(f"âœ… ì¼ë°˜ ì´ë¯¸ì§€ ë°œê²¬: {full_url} (ì ìˆ˜: {score})")
                            if len(image_candidates) >= 10:  # ë„ˆë¬´ ë§ì´ ìˆ˜ì§‘í•˜ì§€ ì•ŠìŒ
                                break
            
            # ì ìˆ˜ì™€ ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì •ë ¬
            image_candidates.sort(key=lambda x: (-x['priority'], -x['score']))
            
            if image_candidates:
                selected_image = image_candidates[0]
                print(f"ğŸ¯ ì„ íƒëœ ì´ë¯¸ì§€: {selected_image['url']} (íƒ€ì…: {selected_image['type']}, ì ìˆ˜: {selected_image['score']})")
                return selected_image['url']
            else:
                print(f"âŒ ìœ íš¨í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {article_url}")
                return None
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨ {article_url}: {e}")
            return None
    
    def _fetch_with_retry(self, url):
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°"""
        for attempt in range(self.max_retries):
            try:
                print(f"ğŸ“¡ ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì‹œë„ {attempt + 1}/{self.max_retries}: {url}")
                response = self.session.get(url, timeout=self.timeout)
                response.raise_for_status()
                print(f"âœ… ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ: {url}")
                return response
            except Exception as e:
                print(f"âš ï¸ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                if attempt < self.max_retries - 1:
                    sleep_time = 2 ** attempt
                    print(f"â³ {sleep_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    time.sleep(sleep_time)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                else:
                    print(f"ğŸ’¥ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {url}")
                    return None
    
    def _is_valid_image_url(self, url):
        """ìœ íš¨í•œ ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸"""
        if not url:
            return False
        
        # ìƒëŒ€ URLì€ ìœ íš¨í•˜ë‹¤ê³  ê°€ì •
        if url.startswith('/'):
            return True
        
        # ì ˆëŒ€ URL ê²€ì¦
        try:
            parsed = urlparse(url)
            if parsed.scheme not in ['http', 'https']:
                return False
            
            # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¥ì í™•ì¸
            image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp']
            path_lower = parsed.path.lower()
            if any(path_lower.endswith(ext) for ext in image_extensions):
                return True
            
            # í™•ì¥ìê°€ ì—†ì–´ë„ ìœ íš¨í•  ìˆ˜ ìˆìŒ (ë™ì  ì´ë¯¸ì§€)
            return True
            
        except Exception:
            return False
    
    def _is_excluded_image(self, url):
        """ì œì™¸ë˜ì–´ì•¼ í•  ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸ (ë¡œê³ , ê´‘ê³  ë“±)"""
        if not url or not isinstance(url, str):
            return True
        
        url_lower = url.lower()
        
        # ë¡œê³  ë° ì•„ì´ì½˜ ê´€ë ¨ í‚¤ì›Œë“œ
        exclude_keywords = [
            'logo', 'icon', 'favicon', 'symbol', 'brand',
            'header', 'footer', 'nav', 'menu', 'sidebar',
            'banner', 'ad', 'advertisement', 'sponsor',
            'social', 'share', 'facebook', 'twitter', 'instagram',
            'avatar', 'profile', 'author', 'writer',
            'button', 'arrow', 'loading', 'spinner',
            'placeholder', 'default', 'blank',
            'thumbnail_default', 'no-image', 'noimage',
            'google', 'youtube', 'naver', 'kakao',  # í”Œë«í¼ ë¡œê³ 
            '1x1', 'pixel', 'tracking',  # ì¶”ì  ì´ë¯¸ì§€
        ]
        
        # URLì— ì œì™¸ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸
        for keyword in exclude_keywords:
            if keyword in url_lower:
                return True
        
        # ë§¤ìš° ì‘ì€ ì´ë¯¸ì§€ ì œì™¸ (URLì— í¬ê¸° ì •ë³´ ìˆì„ ê²½ìš°)
        size_patterns = [
            r'\b\d{1,2}x\d{1,2}\b',  # 50x50 ê°™ì€ ì‘ì€ ì‚¬ì´ì¦ˆ
            r'\b[1-9]\dx[1-9]\d\b'   # 10x10 ~ 99x99
        ]
        
        for pattern in size_patterns:
            if re.search(pattern, url):
                # ì‚¬ì´ì¦ˆ ì¶”ì¶œí•´ì„œ ë„ˆë¬´ ì‘ìœ¼ë©´ ì œì™¸
                match = re.search(r'\b(\d+)x(\d+)\b', url)
                if match:
                    width, height = int(match.group(1)), int(match.group(2))
                    if width < 200 or height < 150:  # 200x150 ë¯¸ë§Œ ì œì™¸
                        return True
        
        return False
    
    def _extract_structured_data_images(self, soup):
        """êµ¬ì¡°í™” ë°ì´í„°(JSON-LD)ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        images = []
        
        try:
            # JSON-LD ìŠ¤í¬ë¦½íŠ¸ ì°¾ê¸°
            json_scripts = soup.find_all('script', type='application/ld+json')
            
            for script in json_scripts:
                try:
                    data = json.loads(script.string)
                    
                    # ì—¬ëŸ¬ í˜•íƒœì˜ ë°ì´í„° ì²˜ë¦¬
                    if isinstance(data, list):
                        for item in data:
                            images.extend(self._extract_images_from_json_ld(item))
                    else:
                        images.extend(self._extract_images_from_json_ld(data))
                        
                except (json.JSONDecodeError, TypeError):
                    continue
                    
        except Exception as e:
            print(f"âš ï¸ JSON-LD ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            
        return images[:3]  # ìµœëŒ€ 3ê°œë§Œ ë°˜í™˜
    
    def _extract_images_from_json_ld(self, data):
        """ê°œë³„ JSON-LD ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        images = []
        
        if not isinstance(data, dict):
            return images
        
        # ë‹¤ì–‘í•œ ì´ë¯¸ì§€ í•„ë“œ ì°¾ê¸°
        image_fields = ['image', 'thumbnailUrl', 'contentUrl', 'url']
        
        for field in image_fields:
            if field in data:
                image_data = data[field]
                
                if isinstance(image_data, str):
                    images.append(image_data)
                elif isinstance(image_data, list):
                    for img in image_data:
                        if isinstance(img, str):
                            images.append(img)
                        elif isinstance(img, dict) and 'url' in img:
                            images.append(img['url'])
                elif isinstance(image_data, dict) and 'url' in image_data:
                    images.append(image_data['url'])
        
        return images
    
    def _calculate_image_score(self, img_element, selector_type):
        """ì´ë¯¸ì§€ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-100)"""
        score = 0
        
        # 1. ê¸°ë³¸ ì ìˆ˜ (ì„ íƒì íƒ€ì…ì— ë”°ë¼)
        base_scores = {
            'article': 60,
            'main': 50, 
            '.article-content': 55,
            '.content': 45,
            '.post-content': 50,
            '.entry-content': 50,
            'general': 20
        }
        
        for key, base_score in base_scores.items():
            if key in selector_type:
                score += base_score
                break
        else:
            score += 20  # ê¸°ë³¸ ì ìˆ˜
        
        # 2. ì´ë¯¸ì§€ í¬ê¸° ì ìˆ˜
        try:
            width = int(img_element.get('width', 0) or 0)
            height = int(img_element.get('height', 0) or 0)
            
            if width >= 600 and height >= 400:  # í° ì´ë¯¸ì§€
                score += 30
            elif width >= 400 and height >= 300:  # ì¤‘ê°„ ì´ë¯¸ì§„
                score += 20
            elif width >= 300 and height >= 200:  # ì‘ì€ ì´ë¯¸ì§„
                score += 10
            elif width > 0 and height > 0 and (width < 150 or height < 100):  # ë„ˆë¬´ ì‘ìŒ
                score -= 20
                
        except (ValueError, TypeError):
            pass
        
        # 3. alt í…ìŠ¤íŠ¸ ì ìˆ˜ (ì˜ë¯¸ìˆëŠ” ì„¤ëª…)
        alt_text = img_element.get('alt', '').lower()
        if alt_text:
            if len(alt_text) > 10:  # ìƒì„¸í•œ alt í…ìŠ¤íŠ¸
                score += 15
            elif len(alt_text) > 3:  # ê¸°ë³¸ alt í…ìŠ¤íŠ¸
                score += 10
            
            # alt í…ìŠ¤íŠ¸ì— ë¡œê³ /ì•„ì´ì½˜ í‚¤ì›Œë“œ ìˆìœ¼ë©´ ê°ì 
            exclude_words = ['logo', 'icon', 'avatar', 'profile', 'button', 'banner']
            if any(word in alt_text for word in exclude_words):
                score -= 25
        
        # 4. CSS í´ë˜ìŠ¤ ì ìˆ˜
        class_names = ' '.join(img_element.get('class', [])).lower()
        if class_names:
            # ê¸´ì •ì  í´ë˜ìŠ¤
            positive_classes = ['article', 'content', 'main', 'featured', 'hero', 'primary']
            for cls in positive_classes:
                if cls in class_names:
                    score += 5
                    break
            
            # ë¶€ì •ì  í´ë˜ìŠ¤
            negative_classes = ['logo', 'icon', 'avatar', 'button', 'banner', 'ad', 'sidebar']
            for cls in negative_classes:
                if cls in class_names:
                    score -= 20
                    break
        
        # 5. data-src ì‚¬ìš© (ì§€ì—° ë¡œë”©) - ì•½ê°„ ê°ì 
        if img_element.get('data-src') and not img_element.get('src'):
            score -= 5
        
        return max(0, min(100, score))  # 0-100 ë²”ìœ„ë¡œ ì œí•œ 