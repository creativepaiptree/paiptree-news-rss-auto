#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
from bs4 import BeautifulSoup
import time
import re
import json
from urllib.parse import urljoin, urlparse
import logging
from PIL import Image
from io import BytesIO
import base64

class ArticleImageScraper:
    def __init__(self, timeout=10, max_retries=3):
        self.timeout = timeout
        self.max_retries = max_retries
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
    
    def extract_largest_image(self, article_url, max_size=(400, 300), return_optimized=True):
        """ğŸ”¥ ê¸°ì‚¬ì—ì„œ ê°€ì¥ í° ì´ë¯¸ì§€ ì¶”ì¶œ - ì‹¤ì œ í¬ê¸° ì¸¡ì •"""
        try:
            print(f"ğŸ” ì´ë¯¸ì§€ ì¶”ì¶œ ì‹œì‘: {article_url}")
            
            # ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
            response = self._fetch_with_retry(article_url)
            if not response:
                print(f"âŒ ì›¹í˜ì´ì§€ ì ‘ê·¼ ì‹¤íŒ¨: {article_url}")
                return None
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ğŸ”¥ ëª¨ë“  ì´ë¯¸ì§€ í›„ë³´ ìˆ˜ì§‘ (ì‹¤ì œ í¬ê¸° ì¸¡ì •ìš©)
            all_image_urls = set()
            
            # 1. og:image ë©”íƒ€ íƒœê·¸
            og_image = soup.find('meta', property='og:image')
            if og_image and og_image.get('content'):
                image_url = og_image['content']
                if self._is_valid_image_url(image_url) and not self._is_excluded_image(image_url):
                    all_image_urls.add(urljoin(article_url, image_url))
                    print(f"âœ… og:image ë°œê²¬: {image_url}")
            
            # 2. ê¸°ì‚¬ ë³¸ë¬¸ ì˜ì—­ ë‚´ ëª¨ë“  ì´ë¯¸ì§€
            article_selectors = [
                'article img', 'main img', '.article-content img',
                '.content img', '.post-content img', '.entry-content img',
                '[data-article] img', '.article-body img', '.news-content img'
            ]
            
            for selector in article_selectors:
                article_images = soup.select(selector)
                for img in article_images:
                    src = img.get('src') or img.get('data-src') or img.get('data-original')
                    if src and self._is_valid_image_url(src) and not self._is_excluded_image(src):
                        full_url = urljoin(article_url, src)
                        all_image_urls.add(full_url)
                        print(f"âœ… ë³¸ë¬¸ ì´ë¯¸ì§€ ë°œê²¬: {src}")
            
            # 3. ì¼ë°˜ ì´ë¯¸ì§€ (ë³¸ë¬¸ì—ì„œ ì¶©ë¶„íˆ ëª» ì°¾ì•˜ì„ ê²½ìš°ë§Œ)
            if len(all_image_urls) < 5:
                general_images = soup.find_all('img', src=True)
                for img in general_images[:10]:  # ìµœëŒ€ 10ê°œë§Œ í™•ì¸
                    src = img.get('src')
                    if src and self._is_valid_image_url(src) and not self._is_excluded_image(src):
                        full_url = urljoin(article_url, src)
                        all_image_urls.add(full_url)
            
            print(f"ğŸ“Š ì´ {len(all_image_urls)}ê°œ ì´ë¯¸ì§€ í›„ë³´ ë°œê²¬")
            
            if not all_image_urls:
                print(f"âŒ ìœ íš¨í•œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {article_url}")
                return None
            
            # ğŸ”¥ í•µì‹¬: ëª¨ë“  ì´ë¯¸ì§€ì˜ ì‹¤ì œ í¬ê¸° ì¸¡ì •
            image_sizes = []
            for img_url in list(all_image_urls)[:15]:  # ìµœëŒ€ 15ê°œë§Œ ì¸¡ì • (ì„±ëŠ¥ ê³ ë ¤)
                actual_size = self._get_actual_image_size(img_url)
                if actual_size:
                    width, height = actual_size
                    area = width * height
                    
                    # ìµœì†Œ í¬ê¸° í•„í„°ë§ (200x150 ì´ìƒ)
                    if width >= 200 and height >= 150:
                        image_sizes.append({
                            'url': img_url,
                            'width': width,
                            'height': height,
                            'area': area
                        })
                        print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {width}x{height} (ë©´ì : {area:,}pxÂ²) - {img_url}")
                    else:
                        print(f"âŒ ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€: {width}x{height} - {img_url}")
                else:
                    print(f"âš ï¸ í¬ê¸° ì¸¡ì • ì‹¤íŒ¨: {img_url}")
            
            # ë©´ì  ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ í° ì´ë¯¸ì§€ ì„ íƒ
            if image_sizes:
                largest_image = max(image_sizes, key=lambda x: x['area'])
                print(f"ğŸ† ê°€ì¥ í° ì´ë¯¸ì§€ ì„ íƒ: {largest_image['width']}x{largest_image['height']} (ë©´ì : {largest_image['area']:,}pxÂ²)")
                print(f"ğŸ¯ ì„ íƒëœ URL: {largest_image['url']}")
                
                # ğŸ”¥ ì´ë¯¸ì§€ ìµœì í™” ì˜µì…˜
                if return_optimized:
                    optimized_image = self._optimize_image(largest_image['url'], max_size)
                    if optimized_image:
                        print(f"âœ… ì´ë¯¸ì§€ ìµœì í™” ì™„ë£Œ: {max_size[0]}x{max_size[1]} ìµœëŒ€ í¬ê¸°")
                        return optimized_image
                    else:
                        print(f"âš ï¸ ìµœì í™” ì‹¤íŒ¨, ì›ë³¸ URL ë°˜í™˜")
                        return largest_image['url']
                else:
                    return largest_image['url']
            else:
                print(f"âŒ ìœ íš¨í•œ í¬ê¸°ì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {article_url}")
                return None
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨ {article_url}: {e}")
            return None
    
    def _get_actual_image_size(self, image_url):
        """ğŸ”¥ ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ì„œ í¬ê¸° ì¸¡ì •"""
        try:
            print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸° ì¸¡ì • ì¤‘: {image_url[:60]}...")
            
            # ì´ë¯¸ì§€ ë¶€ë¶„ ë‹¤ìš´ë¡œë“œ (í—¤ë”ë§Œ ìš°ì„  ì‹œë„)
            response = self.session.get(
                image_url, 
                timeout=self.timeout,
                stream=True,
                headers={'Range': 'bytes=0-2048'}  # ì²˜ìŒ 2KBë§Œ ë‹¤ìš´ë¡œë“œ
            )
            
            if response.status_code not in [200, 206]:  # 206ì€ Partial Content
                print(f"âš ï¸ HTTP {response.status_code}: {image_url}")
                return None
            
            # Content-Type í™•ì¸
            content_type = response.headers.get('content-type', '')
            if not content_type.startswith('image/'):
                print(f"âš ï¸ ì´ë¯¸ì§€ê°€ ì•„ë‹˜: {content_type}")
                return None
            
            # ì´ë¯¸ì§€ ë°ì´í„° ì½ê¸°
            image_data = BytesIO()
            downloaded_size = 0
            max_download = 50 * 1024  # ìµœëŒ€ 50KBê¹Œì§€ë§Œ ë‹¤ìš´ë¡œë“œ
            
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    image_data.write(chunk)
                    downloaded_size += len(chunk)
                    
                    # PILë¡œ í¬ê¸° ì¸¡ì • ì‹œë„ (ë¶€ë¶„ ë°ì´í„°ë¡œë„ ê°€ëŠ¥í•œ ê²½ìš°ê°€ ë§ìŒ)
                    try:
                        image_data.seek(0)
                        with Image.open(image_data) as img:
                            width, height = img.size
                            print(f"âœ… í¬ê¸° ì¸¡ì • ì„±ê³µ: {width}x{height}")
                            return (width, height)
                    except Exception:
                        pass  # ì•„ì§ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŒ
                    
                    # ìµœëŒ€ ë‹¤ìš´ë¡œë“œ í¬ê¸° ì²´í¬
                    if downloaded_size >= max_download:
                        break
            
            # ë§ˆì§€ë§‰ ì‹œë„
            try:
                image_data.seek(0)
                with Image.open(image_data) as img:
                    width, height = img.size
                    print(f"âœ… í¬ê¸° ì¸¡ì • ì„±ê³µ: {width}x{height}")
                    return (width, height)
            except Exception as e:
                print(f"âŒ PIL ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                
                # PIL ì‹¤íŒ¨ì‹œ ì „ì²´ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„
                try:
                    full_response = self.session.get(image_url, timeout=self.timeout)
                    if full_response.status_code == 200:
                        with Image.open(BytesIO(full_response.content)) as img:
                            width, height = img.size
                            print(f"âœ… ì „ì²´ ë‹¤ìš´ë¡œë“œ í›„ í¬ê¸° ì¸¡ì • ì„±ê³µ: {width}x{height}")
                            return (width, height)
                except Exception as e2:
                    print(f"âŒ ì „ì²´ ë‹¤ìš´ë¡œë“œë„ ì‹¤íŒ¨: {e2}")
                
                return None
                
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ í¬ê¸° ì¸¡ì • ì‹¤íŒ¨ {image_url}: {e}")
            return None
    
    # ê¸°ì¡´ í•¨ìˆ˜ë“¤ ìœ ì§€ (í˜¸í™˜ì„±ì„ ìœ„í•´)
    def extract_first_image(self, article_url):
        """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ - ìƒˆë¡œìš´ largest_image í•¨ìˆ˜ í˜¸ì¶œ"""
        return self.extract_largest_image(article_url)
    
    def _fetch_with_retry(self, url):
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°"""
        for attempt in range(self.max_retries):
            try:
                print(f"ğŸ“¡ ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì‹œë„ {attempt + 1}/{self.max_retries}: {url}")
                response = self.session.get(url, timeout=self.timeout)
                response.raise_for_status()
                print(f"âœ… ì›¹í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ: {url}")
                return response
            except Exception as e:
                print(f"âš ï¸ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                if attempt < self.max_retries - 1:
                    sleep_time = 2 ** attempt
                    print(f"â³ {sleep_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    time.sleep(sleep_time)
                else:
                    print(f"ğŸ’¥ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {url}")
                    return None
    
    def _is_valid_image_url(self, url):
        """ìœ íš¨í•œ ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸"""
        if not url:
            return False
        
        # ìƒëŒ€ URLì€ ìœ íš¨í•˜ë‹¤ê³  ê°€ì •
        if url.startswith('/'):
            return True
        
        # ì ˆëŒ€ URL ê²€ì¦
        try:
            parsed = urlparse(url)
            if parsed.scheme not in ['http', 'https']:
                return False
            
            # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¥ì í™•ì¸
            image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp']
            path_lower = parsed.path.lower()
            if any(path_lower.endswith(ext) for ext in image_extensions):
                return True
            
            # í™•ì¥ìê°€ ì—†ì–´ë„ ìœ íš¨í•  ìˆ˜ ìˆìŒ (ë™ì  ì´ë¯¸ì§€)
            return True
            
        except Exception:
            return False
    
    def _is_excluded_image(self, url):
        """ì œì™¸ë˜ì–´ì•¼ í•  ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸ (ë¡œê³ , ê´‘ê³  ë“±)"""
        if not url or not isinstance(url, str):
            return True
        
        url_lower = url.lower()
        
        # ë¡œê³  ë° ì•„ì´ì½˜ ê´€ë ¨ í‚¤ì›Œë“œ (ë” ê°•í™”)
        exclude_keywords = [
            'logo', 'icon', 'favicon', 'symbol', 'brand',
            'header', 'footer', 'nav', 'menu', 'sidebar',
            'banner', 'ad', 'advertisement', 'sponsor',
            'social', 'share', 'facebook', 'twitter', 'instagram',
            'avatar', 'profile', 'author', 'writer', 'reporter',
            'button', 'arrow', 'loading', 'spinner',
            'placeholder', 'default', 'blank', 'thumb',
            'thumbnail_default', 'no-image', 'noimage',
            'google', 'youtube', 'naver', 'kakao', 'daum',
            '1x1', 'pixel', 'tracking', 'analytics',
            'print', 'email', 'bookmark', 'subscribe'
        ]
        
        # URLì— ì œì™¸ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸
        for keyword in exclude_keywords:
            if keyword in url_lower:
                return True
        
        # ë§¤ìš° ì‘ì€ ì´ë¯¸ì§€ ì œì™¸ (URLì— í¬ê¸° ì •ë³´ ìˆì„ ê²½ìš°)
        size_patterns = [
            r'\b\d{1,2}x\d{1,2}\b',  # 50x50 ê°™ì€ ì‘ì€ ì‚¬ì´ì¦ˆ
            r'\b[1-9]\dx[1-9]\d\b'   # 10x10 ~ 99x99
        ]
        
        for pattern in size_patterns:
            if re.search(pattern, url):
                match = re.search(r'\b(\d+)x(\d+)\b', url)
                if match:
                    width, height = int(match.group(1)), int(match.group(2))
                    if width < 200 or height < 150:
                        return True
        
        return False
    
    def _optimize_image(self, image_url, max_size=(400, 300), quality=85):
        """ğŸ”¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í›„ ë¦¬ì‚¬ì´ì§• ë° ì••ì¶•"""
        try:
            print(f"ğŸ“ ì´ë¯¸ì§€ ìµœì í™” ì‹œì‘: {image_url[:60]}...")
            
            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            response = self.session.get(image_url, timeout=self.timeout)
            if response.status_code != 200:
                print(f"âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {response.status_code}")
                return None
            
            # ì´ë¯¸ì§€ ì—´ê¸°
            original_image = Image.open(BytesIO(response.content))
            original_size = original_image.size
            original_format = original_image.format or 'JPEG'
            
            print(f"ğŸ–¼ï¸ ì›ë³¸ ì´ë¯¸ì§€: {original_size[0]}x{original_size[1]} ({original_format})")
            
            # RGB ë¡œ ë³€í™˜ (JPEG ì €ì¥ì„ ìœ„í•´)
            if original_image.mode in ('RGBA', 'LA', 'P'):
                # íˆ¬ëª… ë°°ê²½ì„ í°ìƒ‰ìœ¼ë¡œ ì²˜ë¦¬
                background = Image.new('RGB', original_image.size, (255, 255, 255))
                if original_image.mode == 'P':
                    original_image = original_image.convert('RGBA')
                background.paste(original_image, mask=original_image.split()[-1] if original_image.mode == 'RGBA' else None)
                original_image = background
            elif original_image.mode != 'RGB':
                original_image = original_image.convert('RGB')
            
            # ë¦¬ì‚¬ì´ì§• (ë¹„ìœ¨ ìœ ì§€)
            original_image.thumbnail(max_size, Image.Resampling.LANCZOS)
            new_size = original_image.size
            
            print(f"ğŸ“ ë¦¬ì‚¬ì´ì§• ê²°ê³¼: {new_size[0]}x{new_size[1]}")
            
            # ì••ì¶•ëœ ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
            output_buffer = BytesIO()
            original_image.save(output_buffer, format='JPEG', quality=quality, optimize=True)
            compressed_data = output_buffer.getvalue()
            
            # í¬ê¸° ë¹„êµ
            original_size_kb = len(response.content) / 1024
            compressed_size_kb = len(compressed_data) / 1024
            compression_ratio = (1 - compressed_size_kb / original_size_kb) * 100
            
            print(f"ğŸ“ ì›ë³¸ í¬ê¸°: {original_size_kb:.1f}KB")
            print(f"ğŸ“ ì••ì¶• í¬ê¸°: {compressed_size_kb:.1f}KB")
            print(f"ğŸ“Š ì••ì¶•ë¥ : {compression_ratio:.1f}% ê°ì†Œ")
            
            # Base64 ì¸ì½”ë”©ìœ¼ë¡œ data URL ìƒì„±
            base64_data = base64.b64encode(compressed_data).decode('utf-8')
            data_url = f"data:image/jpeg;base64,{base64_data}"
            
            print(f"âœ… ì´ë¯¸ì§€ ìµœì í™” ì™„ë£Œ!")
            return data_url
            
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ìµœì í™” ì‹¤íŒ¨: {e}")
            return None
    
    def _optimize_image_external(self, image_url, max_size=(400, 300)):
        """ğŸ”¥ ëŒ€ì•ˆ: ì™¸ë¶€ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• ì„œë¹„ìŠ¤ ì‚¬ìš©"""
        try:
            # ì˜ˆì‹œ: Cloudinary, ImageKit ë“±ì˜ URL ë³€í™˜ ì„œë¹„ìŠ¤
            # ì˜ˆ: https://res.cloudinary.com/demo/image/fetch/w_400,h_300,c_fill/https://original-image-url.jpg
            
            # ê°„ë‹¨í•œ ë°©ë²•: URL íŒŒë¼ë¯¸í„° ì¶”ê°€ (ì¼ë¶€ ì„œë¹„ìŠ¤ ì§€ì›)
            if '?' in image_url:
                optimized_url = f"{image_url}&w={max_size[0]}&h={max_size[1]}&q=85"
            else:
                optimized_url = f"{image_url}?w={max_size[0]}&h={max_size[1]}&q=85"
            
            print(f"ğŸ”— ì™¸ë¶€ ë¦¬ì‚¬ì´ì§• URL: {optimized_url}")
            return optimized_url
            
        except Exception as e:
            print(f"âŒ ì™¸ë¶€ ë¦¬ì‚¬ì´ì§• ì‹¤íŒ¨: {e}")
            return image_url  # ì›ë³¸ URL ë°˜í™˜