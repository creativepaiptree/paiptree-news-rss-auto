name: ğŸ“š Paiptree News Initial Collection

on:
  # ìˆ˜ë™ ì‹¤í–‰ ì „ìš© (ì´ˆê¸° ì„¤ì •ì‹œì—ë§Œ ì‚¬ìš©)
  workflow_dispatch:
    inputs:
      collection_mode:
        description: "ìˆ˜ì§‘ ëª¨ë“œ ì„ íƒ"
        required: true
        default: "initial"
        type: choice
        options:
          - initial
          - recent

jobs:
  initial-collection:
    runs-on: ubuntu-latest

    steps:
      - name: ì €ì¥ì†Œ ì²´í¬ì•„ì›ƒ
        uses: actions/checkout@v4

      - name: Python ì„¤ì •
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
          cache: "pip"

      - name: ì˜ì¡´ì„± ì„¤ì¹˜
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: í™˜ê²½ë³€ìˆ˜ ê²€ì¦
        env:
          PAIPTREE_API_URL: ${{ secrets.PAIPTREE_API_URL }}
          NEWS_INGEST_SECRET: ${{ secrets.NEWS_INGEST_SECRET }}
        run: |
          if [[ -z "$PAIPTREE_API_URL" ]]; then
            echo "âŒ PAIPTREE_API_URL ëˆ„ë½"
            exit 1
          fi
          if [[ -z "$NEWS_INGEST_SECRET" ]]; then
            echo "âŒ NEWS_INGEST_SECRET ëˆ„ë½"
            exit 1
          fi
          if [[ ! "$PAIPTREE_API_URL" =~ ^https?:// ]]; then
            echo "âŒ PAIPTREE_API_URL í˜•ì‹ ì˜¤ë¥˜ (http/https í•„ìš”)"
            exit 1
          fi
          echo "âœ… í™˜ê²½ë³€ìˆ˜ í™•ì¸ ì™„ë£Œ"

      - name: ì´ˆê¸° ë‰´ìŠ¤ ëŒ€ëŸ‰ ìˆ˜ì§‘ ì‹¤í–‰
        env:
          INITIAL_COLLECTION: ${{ github.event.inputs.collection_mode == 'initial' && 'true' || 'false' }}
        run: |
          echo "ğŸš€ Paiptree ì´ˆê¸° ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘"
          echo "ğŸ“… ì‹¤í–‰ ì‹œê°„: $(date)"
          echo "ğŸ¯ ìˆ˜ì§‘ ëª¨ë“œ: ${{ github.event.inputs.collection_mode }}"

          if [[ "${{ github.event.inputs.collection_mode }}" == "initial" ]]; then
            echo "ğŸ“š ì´ˆê¸° ëŒ€ëŸ‰ ìˆ˜ì§‘ ëª¨ë“œ: ê°€ëŠ¥í•œ ëª¨ë“  ê³¼ê±° ë‰´ìŠ¤ ìˆ˜ì§‘"
          else
            echo "ğŸ“… ìµœê·¼ ë‰´ìŠ¤ ëª¨ë“œ: ìµœê·¼ ë‰´ìŠ¤ ìˆ˜ì§‘"
          fi

          # ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
          python rss_scraper.py

      - name: ì—…ë¡œë“œ payload ìƒì„± (news/social)
        run: |
          mkdir -p dist
          python - <<'PY'
          import csv, json, hashlib
          from pathlib import Path
          from datetime import datetime

          def stable_id(tab, url, fallback=""):
            if not url:
              base = f"{tab}:{fallback}:{datetime.utcnow().isoformat()}"
            else:
              base = f"{tab}:{url.strip()}"
            return f"{tab}_{hashlib.sha1(base.encode()).hexdigest()[:24]}"

          def parse_int(v):
            try:
              return int(float(str(v).strip()))
            except:
              return 0

          def pick(row, keys, default=""):
            for key in keys:
              val = row.get(key)
              if val is not None and str(val).strip() != "":
                return str(val).strip()
            return default

          def normalize_rows(csv_path, tab):
            rows = []
            with csv_path.open("r", encoding="utf-8-sig", newline="") as f:
              reader = csv.DictReader(f)
              for raw in reader:
                title = pick(raw, ["title"])
                original_url = pick(raw, ["original_url", "originalUrl", "url", "link"])
                if not title or not original_url:
                  continue

                row_tab = pick(raw, ["tab"], tab)
                row_tab = "social" if row_tab == "social" else "news"

                row = {
                  "id": pick(raw, ["id"], stable_id(row_tab, original_url, title)),
                  "tab": row_tab,
                  "title": title,
                  "description": pick(raw, ["description"]),
                  "category": pick(raw, ["category", "source"]),
                  "tags": pick(raw, ["tags"]),
                  "date": pick(raw, ["date", "upload_date", "published_at", "created_at"]),
                  "download_count": parse_int(pick(raw, ["download_count", "downloadCount", "view_count"], "0")),
                  "original_url": original_url
                }
                rows.append(row)
            return rows

          candidates = {
            "news": [
              Path("news_data.csv"),
              Path("paiptree_data - news_data.csv"),
              Path("news_normalized.csv")
            ],
            "social": [
              Path("social_data.csv"),
              Path("paiptree_data - social_data.csv"),
              Path("social_normalized.csv")
            ]
          }

          produced = 0
          for tab, files in candidates.items():
            source = next((p for p in files if p.exists()), None)
            if not source:
              continue
            rows = normalize_rows(source, tab)
            if not rows:
              continue
            out_path = Path(f"dist/{tab}_payload.json")
            out_path.write_text(
              json.dumps({"tab": tab, "rows": rows}, ensure_ascii=False, indent=2),
              encoding="utf-8"
            )
            print(f"âœ… {tab}: {len(rows)} rows -> {out_path}")
            produced += 1

          if produced == 0:
            raise SystemExit("âŒ ì—…ë¡œë“œí•  CSVë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (news/social CSV ìƒì„± ì—¬ë¶€ í™•ì¸)")
          PY

      - name: Paiptree API ì—…ë¡œë“œ
        env:
          PAIPTREE_API_URL: ${{ secrets.PAIPTREE_API_URL }}
          NEWS_INGEST_SECRET: ${{ secrets.NEWS_INGEST_SECRET }}
        run: |
          set -euo pipefail

          for payload in dist/news_payload.json dist/social_payload.json; do
            if [[ ! -f "$payload" ]]; then
              continue
            fi

            echo "ğŸšš ì—…ë¡œë“œ: $payload"
            curl -sS -f -X POST "${PAIPTREE_API_URL}/api/batch/collect-news" \
              -H "Content-Type: application/json" \
              -H "x-news-ingest-secret: ${NEWS_INGEST_SECRET}" \
              --data @"$payload"
            echo ""
          done

      - name: ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
        if: always()
        run: |
          echo "ğŸ‰ ì´ˆê¸° ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ!"
          echo "ğŸ“… ì™„ë£Œ ì‹œê°„: $(date)"
          echo "âœ… ìƒíƒœ: ${{ job.status }}"
          echo ""
          echo "ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:"
          echo "1. Supabaseì—ì„œ tabë³„ ì ì¬ ê±´ìˆ˜ í™•ì¸"
          echo "2. ì •ê¸° ìˆ˜ì§‘ ì›Œí¬í”Œë¡œìš°(news.yml)ë„ ë™ì¼ ë°©ì‹ìœ¼ë¡œ ì „í™˜"
          echo "3. Google Sheets ê´€ë ¨ Secret ì •ë¦¬"
