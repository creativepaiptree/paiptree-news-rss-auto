name: Paiptree News Collector

on:
  schedule:
    # ë§¤ì¼ ì˜¤ì „ 8ì‹œ (KST) = UTC 23ì‹œì— ì‹¤í–‰
    - cron: "0 23 * * *"

  # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥
  workflow_dispatch:

jobs:
  collect-news:
    runs-on: ubuntu-latest

    steps:
      - name: ì €ì¥ì†Œ ì²´í¬ì•„ì›ƒ
        uses: actions/checkout@v4

      - name: Python ì„¤ì •
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
          cache: "pip"

      - name: ì˜ì¡´ì„± ì„¤ì¹˜
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: í™˜ê²½ë³€ìˆ˜ ê²€ì¦
        env:
          PAIPTREE_API_URL: ${{ secrets.PAIPTREE_API_URL }}
          NEWS_INGEST_SECRET: ${{ secrets.NEWS_INGEST_SECRET }}
        run: |
          if [[ -z "$PAIPTREE_API_URL" ]]; then
            echo "âŒ PAIPTREE_API_URL ëˆ„ë½"
            exit 1
          fi
          if [[ -z "$NEWS_INGEST_SECRET" ]]; then
            echo "âŒ NEWS_INGEST_SECRET ëˆ„ë½"
            exit 1
          fi
          if [[ ! "$PAIPTREE_API_URL" =~ ^https?:// ]]; then
            echo "âŒ PAIPTREE_API_URL í˜•ì‹ ì˜¤ë¥˜ (http/https í•„ìš”)"
            exit 1
          fi
          echo "âœ… í™˜ê²½ë³€ìˆ˜ í™•ì¸ ì™„ë£Œ"

      - name: ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤í–‰ (ì¬ì‹œë„ í¬í•¨)
        id: scrape
        env:
          INITIAL_COLLECTION: "false"
          CONTENT_TAB: "news"
          OUTPUT_JSON_PATH: "dist/news_payload.json"
          OUTPUT_CSV_PATH: "news_data.csv"
        run: |
          set -euo pipefail

          echo "ğŸš€ Paiptree ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘"
          echo "ğŸ“… ì‹¤í–‰ ì‹œê°„: $(date)"

          output_log="scrape_output.log"
          rm -f "$output_log"

          for i in {1..3}; do
            if python rss_scraper.py | tee -a "$output_log"; then
              echo "âœ… ìˆ˜ì§‘ ì„±ê³µ!"
              if [[ -f dist/news_payload.json ]]; then
                count=$(python - <<'PY'
          import json
          try:
              with open("dist/news_payload.json", "r", encoding="utf-8") as f:
                  data = json.load(f)
              print(len(data.get("rows", [])))
          except Exception:
              print(0)
          PY
                )
                echo "result_summary=ìˆ˜ì§‘ ì™„ë£Œ (${count}ê±´ payload ìƒì„±)" >> "$GITHUB_OUTPUT"
                exit 0
              else
                echo "âŒ dist/news_payload.json íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
              fi
            else
              echo "âŒ ì‹œë„ $i ì‹¤íŒ¨"
            fi

            if [[ $i -eq 3 ]]; then
              echo "ğŸ’¥ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨"
              echo "result_summary=ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨" >> "$GITHUB_OUTPUT"
              exit 1
            fi
            sleep 30
          done

      - name: Supabase API ì—…ë¡œë“œ (ì¬ì‹œë„ í¬í•¨)
        id: upload
        env:
          PAIPTREE_API_URL: ${{ secrets.PAIPTREE_API_URL }}
          NEWS_INGEST_SECRET: ${{ secrets.NEWS_INGEST_SECRET }}
        run: |
          set -euo pipefail

          echo "ğŸšš Supabase API ì—…ë¡œë“œ ì‹œì‘"

          for i in {1..3}; do
            status=$(curl -sS -o upload_response.json -w "%{http_code}" \
              -X POST "${PAIPTREE_API_URL}/api/batch/collect-news" \
              -H "Content-Type: application/json" \
              -H "x-news-ingest-secret: ${NEWS_INGEST_SECRET}" \
              --data @dist/news_payload.json || echo "000")

            echo "HTTP ìƒíƒœì½”ë“œ: $status"
            cat upload_response.json || true

            if [[ "$status" == "200" ]]; then
              upserted=$(python - <<'PY'
          import json
          try:
              with open("upload_response.json", "r", encoding="utf-8") as f:
                  data = json.load(f)
              print(data.get("upserted", 0))
          except Exception:
              print(0)
          PY
              )
              echo "result_summary=ì—…ë¡œë“œ ì„±ê³µ (${upserted}ê±´ upsert)" >> "$GITHUB_OUTPUT"
              echo "âœ… ì—…ë¡œë“œ ì„±ê³µ"
              exit 0
            fi

            echo "âŒ ì—…ë¡œë“œ ì‹œë„ $i ì‹¤íŒ¨"
            if [[ $i -eq 3 ]]; then
              echo "result_summary=ì—…ë¡œë“œ ì‹¤íŒ¨ (HTTP ${status})" >> "$GITHUB_OUTPUT"
              exit 1
            fi
            sleep 20
          done

      - name: Discord ì•Œë¦¼ ì „ì†¡
        if: always()
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          if [ -z "$DISCORD_WEBHOOK_URL" ]; then
            echo "âš ï¸ Discord ì›¹í›… URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•Œë¦¼ì„ ê±´ë„ˆëœë‹ˆë‹¤."
            exit 0
          fi

          STATUS="${{ job.status }}"
          if [ "$STATUS" == "success" ]; then
            COLOR=2664261
            STATUS_MSG="ì„±ê³µ"
          else
            COLOR=14502728
            STATUS_MSG="ì‹¤íŒ¨"
          fi

          SCRAPE_SUMMARY="${{ steps.scrape.outputs.result_summary || 'ìˆ˜ì§‘ ì •ë³´ ì—†ìŒ' }}"
          UPLOAD_SUMMARY="${{ steps.upload.outputs.result_summary || 'ì—…ë¡œë“œ ì •ë³´ ì—†ìŒ' }}"

          JSON_PAYLOAD=$(cat <<EOF
          {
            "embeds": [{
              "title": "ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ê²°ê³¼: ${STATUS_MSG}",
              "description": "**Paiptree ë‰´ìŠ¤ ìë™ ìˆ˜ì§‘ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.**\n\n- **ê²°ê³¼**: ${STATUS_MSG}\n- **ìˆ˜ì§‘**: ${SCRAPE_SUMMARY}\n- **ì—…ë¡œë“œ**: ${UPLOAD_SUMMARY}\n- **ì›Œí¬í”Œë¡œìš°**: ${{ github.workflow }}\n\n[ğŸ”— ì‹¤í–‰ ë¡œê·¸ ë°”ë¡œê°€ê¸°](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})",
              "color": ${COLOR},
              "footer": {
                "text": "Paiptree News Collector"
              },
              "timestamp": "$(date -u +'%Y-%m-%dT%H:%M:%S.000Z')"
            }]
          }
          EOF
          )

          curl -X POST -H "Content-Type: application/json" -d "$JSON_PAYLOAD" "$DISCORD_WEBHOOK_URL"
